{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06195e92",
   "metadata": {},
   "source": [
    "<b><font size=\"+2\">Libraries</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "428e6b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "### Python version: 3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]\n",
      "### NumPy version: 1.26.4\n",
      "### Scikit-learn version: 1.4.2\n",
      "### Tensorflow version: 2.16.1\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Load packages we need\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "#import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.datasets import fashion_mnist, cifar10, imdb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import layers and callbacks we may use (may not be a complete list)\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import MobileNetV2\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "#%load_ext tensorboard\n",
    "\n",
    "\n",
    "# Let's check our software versions\n",
    "print('------------')\n",
    "print('### Python version: ' + __import__('sys').version)\n",
    "print('### NumPy version: ' + np.__version__)\n",
    "print('### Scikit-learn version: ' + sklearn.__version__)\n",
    "print('### Tensorflow version: ' + tf.__version__)\n",
    "print('------------')\n",
    "\n",
    "def var_exists(var_name):\n",
    "    return (var_name in globals() or var_name in locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bece2ae",
   "metadata": {},
   "source": [
    "<b><font size=\"+2\">Read Data</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e41e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (7316, 224, 224, 3)\n",
      "Shape of y_train: (7316, 4)\n",
      "Shape of X_val: (1645, 224, 224, 3)\n",
      "Shape of y_val: (1645, 4)\n",
      "Shape of X_test: (184, 224, 224, 3)\n",
      "Shape of y_test: (184, 4)\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing the data\n",
    "data_dir = 'Corn (Maize)'\n",
    "\n",
    "# Define the categories (folder names)\n",
    "categories = ['Cercospora Leaf Spot', 'Common Rust ', 'Healthy', 'Northern Leaf Blight']\n",
    "\n",
    "# Initialize lists to store filenames and labels\n",
    "train_filenames = []\n",
    "val_filenames = []\n",
    "test_filenames = []\n",
    "train_labels = []\n",
    "val_labels = []\n",
    "test_labels = []\n",
    "\n",
    "# Load training data\n",
    "for category_id, category in enumerate(categories):\n",
    "    train_category_dir = os.path.join(data_dir, 'Train', category)\n",
    "    for filename in os.listdir(train_category_dir):\n",
    "        if filename.endswith('.JPG') or filename.endswith('.jpg'):  # Assuming images are jpg or png format\n",
    "            train_filenames.append(os.path.join(train_category_dir, filename))\n",
    "            train_labels.append(category_id)\n",
    "\n",
    "# Load validation data\n",
    "for category_id, category in enumerate(categories):\n",
    "    val_category_dir = os.path.join(data_dir, 'Val', category)\n",
    "    for filename in os.listdir(val_category_dir):\n",
    "        if filename.endswith('.JPG') or filename.endswith('.jpg'):  # Assuming images are jpg or png format\n",
    "            val_filenames.append(os.path.join(val_category_dir, filename))\n",
    "            val_labels.append(category_id)\n",
    "\n",
    "# Load test data\n",
    "for category_id, category in enumerate(categories):\n",
    "    test_category_dir = os.path.join(data_dir, 'Test', category)\n",
    "    for filename in os.listdir(test_category_dir):\n",
    "        if filename.endswith('.JPG') or filename.endswith('.jpg'):  # Assuming images are jpg or png format\n",
    "            test_filenames.append(os.path.join(test_category_dir, filename))\n",
    "            test_labels.append(category_id)\n",
    "\n",
    "# Convert integer labels to one-hot encoded vectors\n",
    "num_classes = len(categories)\n",
    "y_train = to_categorical(train_labels, num_classes=num_classes)\n",
    "y_val = to_categorical(val_labels, num_classes=num_classes)\n",
    "y_test = to_categorical(test_labels, num_classes=num_classes)\n",
    "\n",
    "# Define a function to load and preprocess images\n",
    "def load_and_preprocess_image(image_path):\n",
    "    # Load image from file\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    # Convert image to numpy array\n",
    "    img_array = img_to_array(img)\n",
    "    # Preprocess the image (e.g., normalization)\n",
    "    img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
    "    return img_array\n",
    "\n",
    "# Load and preprocess training images\n",
    "X_train = np.array([load_and_preprocess_image(filename) for filename in train_filenames])\n",
    "\n",
    "# Load and preprocess validation images\n",
    "X_val = np.array([load_and_preprocess_image(filename) for filename in val_filenames])\n",
    "\n",
    "# Load and preprocess test images\n",
    "X_test = np.array([load_and_preprocess_image(filename) for filename in test_filenames])\n",
    "\n",
    "# Check the shapes of the training, validation, and test data\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972630f",
   "metadata": {},
   "source": [
    "# Baseline 1: Most frequent class predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1947f341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy on Validation Set: 0.260790273556231\n",
      "Baseline Model Accuracy on Test Set: 0.2608695652173913\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Find the most frequent class in the training labels\n",
    "most_frequent_class = np.argmax(np.bincount(train_labels))\n",
    "\n",
    "y_train_reshaped = y_train.argmax(axis=1).reshape(-1, 1)\n",
    "dummy_classifier = DummyClassifier(strategy=\"constant\", constant=most_frequent_class)\n",
    "dummy_classifier.fit(X_train, y_train_reshaped)\n",
    "\n",
    "# Predict on validation and test sets\n",
    "y_pred_val = dummy_classifier.predict(X_val)\n",
    "y_pred_test = dummy_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on validation and test sets\n",
    "accuracy_val = accuracy_score(y_val.argmax(axis=1), y_pred_val)\n",
    "accuracy_test = accuracy_score(y_test.argmax(axis=1), y_pred_test)\n",
    "\n",
    "print(\"Baseline Model Accuracy on Validation Set:\", accuracy_val)\n",
    "print(\"Baseline Model Accuracy on Test Set:\", accuracy_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd8bf2",
   "metadata": {},
   "source": [
    "<b><font size=\"+2\">CNN Model</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfec880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_compile_cnn(input_shape=[224, 224, 3], num_outputs=4, verbose=False):\n",
    "    cnn_model = Sequential(name='CNN')\n",
    "    \n",
    "    cnn_model.add(Conv2D(16, kernel_size=(3, 3), input_shape=input_shape, activation='relu', \n",
    "                     padding='same', strides=(1, 1), kernel_initializer='lecun_uniform', name='conv1'))\n",
    "    cnn_model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', \n",
    "                     padding='same', strides=(1, 1), kernel_initializer='lecun_uniform', name='conv2'))\n",
    "    cnn_model.add(MaxPooling2D((2, 2), name='MaxPool1'))\n",
    "    \n",
    "    cnn_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', \n",
    "                     padding='same', strides=(1, 1), kernel_initializer='lecun_uniform', name='conv3'))\n",
    "    cnn_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', \n",
    "                     padding='same', strides=(1, 1), kernel_initializer='lecun_uniform', name='conv4'))\n",
    "    cnn_model.add(MaxPooling2D((2, 2), name='MaxPool2'))\n",
    "    \n",
    "    cnn_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', \n",
    "                     padding='same', strides=(1, 1), kernel_initializer='lecun_uniform', name='conv5'))\n",
    "    cnn_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', \n",
    "                     padding='same', strides=(1, 1), kernel_initializer='lecun_uniform', name='conv6'))\n",
    "    cnn_model.add(MaxPooling2D((2, 2), name='MaxPool3'))\n",
    "    \n",
    "    cnn_model.add(Flatten(name='flatten'))\n",
    "    \n",
    "    cnn_model.add(Dense(64, activation='relu', kernel_initializer='lecun_uniform', name='dense1'))\n",
    "    cnn_model.add(Dropout(0.25, name='drop1'))\n",
    "    \n",
    "    cnn_model.add(Dense(32, activation='relu', kernel_initializer='lecun_uniform', name='dense2'))\n",
    "    cnn_model.add(Dropout(0.25, name='drop2'))\n",
    "    \n",
    "    cnn_model.add(Dense(num_outputs, activation='softmax', name='output'))\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    if verbose:\n",
    "        cnn_model.summary()\n",
    "    \n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162f275",
   "metadata": {},
   "source": [
    "<b><font size=\"+2\">Compile CNN</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c58262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pablo/Documents/Spring/Machine learning/tens_env/tfvenv/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPool3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ drop1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ drop2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m2,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv4 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv5 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv6 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPool3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m3,211,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ drop1 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense2 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ drop2 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,285,620</span> (12.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,285,620\u001b[0m (12.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,285,620</span> (12.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,285,620\u001b[0m (12.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_model = create_compile_cnn(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d212d83d",
   "metadata": {},
   "source": [
    "<b><font size=\"+2\">Fit Model</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b324bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 1s/step - accuracy: 0.5002 - loss: 1.1294 - val_accuracy: 0.5763 - val_loss: 0.8224\n",
      "Epoch 2/15\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.6059 - loss: 0.7691 - val_accuracy: 0.7842 - val_loss: 0.4896\n",
      "Epoch 3/15\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.8337 - loss: 0.4403 - val_accuracy: 0.9362 - val_loss: 0.1821\n",
      "Epoch 4/15\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 1s/step - accuracy: 0.9279 - loss: 0.2088 - val_accuracy: 0.9526 - val_loss: 0.1321\n",
      "Epoch 5/15\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.9372 - loss: 0.1804 - val_accuracy: 0.9447 - val_loss: 0.1419\n",
      "Epoch 6/15\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 1s/step - accuracy: 0.9536 - loss: 0.1341 - val_accuracy: 0.9228 - val_loss: 0.2299\n",
      "Epoch 7/15\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - accuracy: 0.9372 - loss: 0.1912 - val_accuracy: 0.9587 - val_loss: 0.1184\n",
      "Epoch 8/15\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 2s/step - accuracy: 0.9514 - loss: 0.1389 - val_accuracy: 0.9635 - val_loss: 0.0952\n",
      "Epoch 9/15\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - accuracy: 0.9626 - loss: 0.1092 - val_accuracy: 0.9477 - val_loss: 0.1279\n",
      "Epoch 10/15\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 2s/step - accuracy: 0.9668 - loss: 0.0931 - val_accuracy: 0.9714 - val_loss: 0.0819\n",
      "Epoch 11/15\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 1s/step - accuracy: 0.9746 - loss: 0.0766 - val_accuracy: 0.9660 - val_loss: 0.0907\n",
      "Epoch 12/15\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 2s/step - accuracy: 0.9735 - loss: 0.0870 - val_accuracy: 0.9599 - val_loss: 0.1060\n",
      "Epoch 13/15\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - accuracy: 0.9596 - loss: 0.1370 - val_accuracy: 0.9617 - val_loss: 0.0979\n",
      "Epoch 14/15\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 2s/step - accuracy: 0.9802 - loss: 0.0619 - val_accuracy: 0.9690 - val_loss: 0.0839\n",
      "Epoch 15/15\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 2s/step - accuracy: 0.9825 - loss: 0.0529 - val_accuracy: 0.9653 - val_loss: 0.1004\n"
     ]
    }
   ],
   "source": [
    "early_stop_cb = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "max_epochs = 15\n",
    "batch_size = 64\n",
    "    \n",
    "cnn_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=max_epochs, batch_size=batch_size, \n",
    "                         shuffle=True, callbacks=[early_stop_cb])\n",
    "\n",
    "# Save the model\n",
    "cnn_model.save('cnn.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e39836",
   "metadata": {},
   "source": [
    "<b><font size=\"+2\">MobileNetV2 Model</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a25e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - accuracy: 0.8433 - loss: 0.4916"
     ]
    }
   ],
   "source": [
    "# Load pre-trained MobileNetV2 model without the top (classification) layer\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Combine base model with custom head\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop_cb = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "max_epochs = 10\n",
    "batch_size = 64\n",
    "    \n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=max_epochs, batch_size=batch_size, \n",
    "                         shuffle=True, callbacks=[early_stop_cb])\n",
    "\n",
    "# Save the model\n",
    "model.save('mobv2.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc390f22",
   "metadata": {},
   "source": [
    "<b><font size=\"+2\">Readable Predictions</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to make readable predictions\n",
    "def readable_prediction(image_path, m, categories):\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)  # Preprocess the image as needed\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = m.predict(img_array)\n",
    "    \n",
    "    # Print predictions in a readable form\n",
    "    print('Predictions:')\n",
    "    for pred in predictions:\n",
    "        predicted_class_index = np.argmax(pred)\n",
    "        confidence = np.max(pred)\n",
    "        predicted_class_label = categories[predicted_class_index]\n",
    "        print(f\"Class: {predicted_class_label}, Confidence: {confidence}\")\n",
    "\n",
    "def get_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')        \n",
    "    plt.show()\n",
    "\n",
    "# The following is an image path for an image. It gives the confidence level of the prediction made for the image\n",
    "image_path = 'Corn (Maize)/Val/Common Rust/RS_Rust 1659.JPG'\n",
    "categories = ['Cercospora Leaf Spot', 'Common Rust', 'Healthy', 'Northern Leaf Blight']\n",
    "\n",
    "get_image(image_path)\n",
    "\n",
    "print('CNN MODEL:')\n",
    "readable_prediction(image_path, cnn_model, categories)\n",
    "print('\\n')\n",
    "print('MOBILEV2 MODEL:')\n",
    "readable_prediction(image_path, model, categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a10a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model' is your trained model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Convert one-hot encoded labels to integer labels\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print('Confusion Matrix for MobileNetV2:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Labels for the classes\n",
    "class_labels = ['Cercospora Leaf Spot', 'Common Rust', 'Healthy', 'Northern Leaf Blight']\n",
    "\n",
    "# Create a heatmap with annotations\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Greens', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix: MobileNetV2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = cnn_model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_probs = cnn_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Convert one-hot encoded labels to integer labels\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print('Confusion Matrix for CNN:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Labels for the classes\n",
    "class_labels = ['Cercospora Leaf Spot', 'Common Rust', 'Healthy', 'Northern Leaf Blight']\n",
    "\n",
    "# Create a heatmap with annotations\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Reds', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix: CNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e635674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b120331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfvenv",
   "language": "python",
   "name": "tfvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
